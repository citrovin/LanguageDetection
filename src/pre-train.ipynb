{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Detection on the Edge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import wave\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation, GlobalAveragePooling1D\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_generator(dataset_dir: str, file_names: list):\n",
    "    \n",
    "    x_train, x_test, x_val, y_train, y_test, y_val = [], [], [], [], [], []\n",
    "    \n",
    "    for enum, file in enumerate(file_names):\n",
    "        path = dataset_dir + file + '.pkl'\n",
    "        with open(path, 'rb') as data_file:\n",
    "            data = pickle.load(data_file)\n",
    "\n",
    "            data_train = data['data_train']\n",
    "            data_test = data['data_test']\n",
    "            data_val = data['data_val']\n",
    "\n",
    "        sample_rate=16000\n",
    "\n",
    "        x_train_inter = []\n",
    "        for i in data_train:\n",
    "            num_sec = int(i.shape[0]/sample_rate)\n",
    "            array_intermediate = i[:(num_sec*sample_rate)]\n",
    "            x_train_inter.extend(np.split(array_intermediate, num_sec))\n",
    "        \n",
    "\n",
    "        x_test_inter = []\n",
    "        for i in data_test:\n",
    "            num_sec = int(i.shape[0]/sample_rate)\n",
    "            array_intermediate = i[:(num_sec*sample_rate)]\n",
    "            x_test_inter.extend(np.split(array_intermediate, num_sec))\n",
    "\n",
    "        x_val_inter = []\n",
    "        for i in data_val:\n",
    "            num_sec = int(i.shape[0]/sample_rate)\n",
    "            array_intermediate = i[:(num_sec*sample_rate)]\n",
    "            x_val_inter.extend(np.split(array_intermediate, num_sec))\n",
    "\n",
    "        y_train_inter = [[enum]]*len(x_train_inter)\n",
    "        y_test_inter = [[enum]]*len(x_test_inter)\n",
    "        y_val_inter = [[enum]]*len(x_val_inter)\n",
    "\n",
    "        x_train.extend(x_train_inter)\n",
    "        x_test.extend(x_test_inter)\n",
    "        x_val.extend(x_val_inter)\n",
    "\n",
    "        y_train.extend(y_train_inter)\n",
    "        y_test.extend(y_test_inter)\n",
    "        y_val.extend(y_val_inter)\n",
    "        \n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    x_val = np.array(x_val)\n",
    "    \n",
    "    y_train = to_categorical(np.array(y_train))\n",
    "    y_test = to_categorical(np.array(y_test))\n",
    "    y_val = to_categorical(np.array(y_val))\n",
    "\n",
    "    return x_train, x_test, x_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "Number of samples in train: 127843\n",
      "Number of samples in test: 40575\n",
      "Number of samplesin validation: 17137\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "x_train shape: (127843, 16000) | y_train shape: (127843, 4)\n",
      "x_test shape: (40575, 16000) | y_test shape: (40575, 4)\n",
      "x_val shape: (17137, 16000) | y_val shape: (17137, 4)\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '../data/pre-train/raw/'\n",
    "CLASSES = ['fleurs.de_de', 'fleurs.es_419', 'fleurs.fr_fr', 'fleurs.it_it']\n",
    "\n",
    "x_train, x_test, x_val, y_train, y_test, y_val = load_data_generator(dataset_dir, CLASSES)\n",
    "\n",
    "print('----------------------------------------------------------------------')\n",
    "print(f'Number of samples in train: {len(x_train)}')\n",
    "print(f'Number of samples in test: {len(x_test)}')\n",
    "print(f'Number of samplesin validation: {len(x_val)}')\n",
    "print('----------------------------------------------------------------------')\n",
    "print('----------------------------------------------------------------------')\n",
    "print(f'x_train shape: {x_train.shape} | y_train shape: {y_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape} | y_test shape: {y_test.shape}')\n",
    "print(f'x_val shape: {x_val.shape} | y_val shape: {y_val.shape}')\n",
    "print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Show distrubution of the labels!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perms = np.random.permutation(len(y_test))[0:250]\n",
    "# x_test_250 = x_test[perms]\n",
    "# y_test_250 = y_test[perms]\n",
    "# np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "# np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Name of Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Available devices\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print('Name of Devices: ', tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 18:42:14.801148: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-28 18:42:14.802668: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 3981, 128)         10368     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 995, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 993, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 248, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 246, 256)          98560     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 61, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 59, 512)           393728    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 14, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7168)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 28676     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 580,612\n",
      "Trainable params: 580,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/OpenSesame/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(Conv1D(filters = 128, kernel_size = 80, strides = 4 )) \n",
    "model.add(MaxPool1D(pool_size = 4)) \n",
    "model.add(Conv1D(filters = 128, kernel_size = 3, strides = 1 )) \n",
    "model.add(MaxPool1D(pool_size = 4)) \n",
    "model.add(Conv1D(filters = 256, kernel_size = 3, strides = 1 )) \n",
    "model.add(MaxPool1D(pool_size = 4)) \n",
    "model.add(Conv1D(filters = 512, kernel_size = 3, strides = 1 )) \n",
    "model.add(MaxPool1D(pool_size = 4)) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(CLASSES)))\n",
    "model.add(Activation('softmax')) \n",
    "\n",
    "# EXPLORE Learning Rate\n",
    "callbacks = EarlyStopping(monitor = \"val_loss\", patience  = 5)\n",
    "opt = tf.keras.optimizers.Adam(lr=10e-4, decay = 10e-6)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 18:43:10.747827: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-28 18:43:12.228659: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998/1998 [==============================] - ETA: 0s - loss: 1.3867 - categorical_accuracy: 0.2713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 18:47:19.417854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998/1998 [==============================] - 276s 137ms/step - loss: 1.3867 - categorical_accuracy: 0.2713 - val_loss: 1.3998 - val_categorical_accuracy: 0.1646\n"
     ]
    }
   ],
   "source": [
    "# Training model with GPU\n",
    "with tf.device('/gpu:0'):\n",
    "  model.fit(x_train, y_train, epochs=1, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268/1268 - 32s - loss: 1.3997 - categorical_accuracy: 0.1646 - 32s/epoch - 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 18:49:01.813486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    0     0 10926     0]\n",
      " [    0     0 10693     0]\n",
      " [    0     0  6680     0]\n",
      " [    0     0 12276     0]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.evaluate(x_test, y_test, verbose=2)\n",
    "    pred_test = model.predict(x_test)\n",
    "    print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSesame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
