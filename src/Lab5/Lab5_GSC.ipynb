{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, cache and extract Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path('datasets')\n",
    "if not (dataset_dir/'testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "    get_file(None, \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
    "                    extract=True,\n",
    "                    file_hash=\"6b74f3901214cb2c2934e98196829835\",\n",
    "                    cache_dir='.',\n",
    "                    cache_subdir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw spoken digits data from Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to handle, ordered by label\n",
    "CLASSES = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "with (dataset_dir/'testing_list.txt').open() as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for recording in dataset_dir.glob(f'**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES: # Ignore unused classes\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name) # Assign class number\n",
    "    \n",
    "    with wave.open(str(recording)) as f: # Read wave file\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy() # As 16-bit signed integer\n",
    "        \n",
    "    data = data.astype(np.float32) # Convert to 32-bit floating-point\n",
    "    data.resize((16000, 1)) # Resize to 1s (16kHz) with zero-padding, 1 channel\n",
    "\n",
    "    if str(recording.relative_to(dataset_dir)) in testing_list: # Assign to test set if file in test list\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference with fixed-point Q7.9 samples by scaling input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 3993, 4)           132       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 998, 4)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 991, 8)            264       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 247, 8)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1976)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                19770     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,166\n",
      "Trainable params: 20,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000,1)))\n",
    "model.add(Conv1D(kernel_size=32, filters=4, strides=4))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "model.add(Conv1D(kernel_size=8, filters=8, strides=1))\n",
    "model.add(MaxPool1D(pool_size=4))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax')) \n",
    "\n",
    "# EXPLORE Learning Rate\n",
    "# callbacks = EarlyStopping(monitor = \"val_loss\", patience  = 5)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 17:19:34.098724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - ETA: 0s - loss: 2.4790 - categorical_accuracy: 0.3355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 17:19:39.770974: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 6s 60ms/step - loss: 2.4790 - categorical_accuracy: 0.3355 - val_loss: 1.6167 - val_categorical_accuracy: 0.4653\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.5028 - categorical_accuracy: 0.5135 - val_loss: 1.5871 - val_categorical_accuracy: 0.4624\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.4464 - categorical_accuracy: 0.5331 - val_loss: 1.6257 - val_categorical_accuracy: 0.4838\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.4254 - categorical_accuracy: 0.5344 - val_loss: 1.7117 - val_categorical_accuracy: 0.4505\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.3604 - categorical_accuracy: 0.5573 - val_loss: 1.6934 - val_categorical_accuracy: 0.4843\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 5s 53ms/step - loss: 1.3140 - categorical_accuracy: 0.5680 - val_loss: 1.7081 - val_categorical_accuracy: 0.4777\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.3089 - categorical_accuracy: 0.5680 - val_loss: 1.7697 - val_categorical_accuracy: 0.4643\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2977 - categorical_accuracy: 0.5764 - val_loss: 1.8507 - val_categorical_accuracy: 0.4638\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.3051 - categorical_accuracy: 0.5687 - val_loss: 1.9252 - val_categorical_accuracy: 0.4714\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.3253 - categorical_accuracy: 0.5698 - val_loss: 1.7390 - val_categorical_accuracy: 0.4724\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2266 - categorical_accuracy: 0.5927 - val_loss: 1.6830 - val_categorical_accuracy: 0.4953\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2433 - categorical_accuracy: 0.5894 - val_loss: 1.8277 - val_categorical_accuracy: 0.4789\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2204 - categorical_accuracy: 0.5938 - val_loss: 1.7258 - val_categorical_accuracy: 0.4855\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2520 - categorical_accuracy: 0.5846 - val_loss: 1.9118 - val_categorical_accuracy: 0.4458\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 5s 53ms/step - loss: 1.2821 - categorical_accuracy: 0.5810 - val_loss: 1.8607 - val_categorical_accuracy: 0.4470\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 5s 53ms/step - loss: 1.2449 - categorical_accuracy: 0.5857 - val_loss: 1.7858 - val_categorical_accuracy: 0.4816\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 5s 54ms/step - loss: 1.2287 - categorical_accuracy: 0.5949 - val_loss: 2.0049 - val_categorical_accuracy: 0.4638\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2048 - categorical_accuracy: 0.5991 - val_loss: 1.7077 - val_categorical_accuracy: 0.5043\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.1772 - categorical_accuracy: 0.6092 - val_loss: 1.8715 - val_categorical_accuracy: 0.4821\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 5s 52ms/step - loss: 1.2677 - categorical_accuracy: 0.5817 - val_loss: 1.8494 - val_categorical_accuracy: 0.4862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x292c90ca0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=384, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 - 1s - loss: 1.8494 - categorical_accuracy: 0.4862 - 917ms/epoch - 7ms/step\n",
      " 35/129 [=======>......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 17:21:21.674010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 5ms/step\n",
      "tf.Tensor(\n",
      "[[194   3  49  28  18  14   8  59  31  14]\n",
      " [ 12 195   6  12  26  46   1   6   3  92]\n",
      " [ 78  12 114 103  16   2  10  16  64   9]\n",
      " [ 45   0  50 178   4   5  15  12  86  10]\n",
      " [ 19  72  35   9 221  27   0  12   3   2]\n",
      " [ 13 104   1   4  14 156   2  27   5 119]\n",
      " [ 11   3  15   7   2   1 234  63  58   0]\n",
      " [ 32  19  30  15  18   8  22 240   7  15]\n",
      " [ 25   2  36  75   6   2  29  12 217   4]\n",
      " [ 10  42   9  15   8  35   0  28  13 248]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 0s - loss: 1.8199 - categorical_accuracy: 0.4560 - 86ms/epoch - 11ms/step\n",
      "8/8 [==============================] - 0s 7ms/step\n",
      "tf.Tensor(\n",
      "[[10  0  3  1  5  2  1  3  1  0]\n",
      " [ 1 14  0  0  1  4  0  0  0  3]\n",
      " [ 6  1  7  5  2  0  0  1  6  0]\n",
      " [ 3  0  5 13  0  0  0  1  6  0]\n",
      " [ 2  6  2  1 17  0  0  1  0  0]\n",
      " [ 1  5  0  0  1  8  0  2  0  7]\n",
      " [ 1  1  1  1  0  0 12  5  6  0]\n",
      " [ 1  2  2  0  1  2  5 12  0  2]\n",
      " [ 1  0  2  4  0  0  2  0 10  0]\n",
      " [ 1  0  1  1  0  3  0  1  1 11]], shape=(10, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install MicroAI for C inference code generation (kerascnn2c module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
      "  Downloading https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip (1.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/embeddedAI/lib/python3.10/site-packages (from kerascnn2c==1.0.0) (1.23.5)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/embeddedAI/lib/python3.10/site-packages (from kerascnn2c==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/embeddedAI/lib/python3.10/site-packages (from jinja2->kerascnn2c==1.0.0) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Invalid requirement: 'https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed' ignored - the uninstall command expects named requirements.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: You must give at least one requirement to uninstall (see \"pip help uninstall\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install https://bitbucket.org/edge-team-leat/microai_public/get/6adfbcb347d3.zip#subdirectory=third_party/kerascnn2c_fixed\n",
    "\n",
    "import kerascnn2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9b2d956c-1708-496d-9c47-1c8cb4fc5b2c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9b2d956c-1708-496d-9c47-1c8cb4fc5b2c/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_6                          | conv1d_4                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_6                          | conv1d_4                         | max_pooling1d_2                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_4                         | max_pooling1d_2                  | conv1d_5                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_2                  | conv1d_5                         | max_pooling1d_3                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_5                         | max_pooling1d_3                  | flatten_3                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_3                  | flatten_3                        | dense_3                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_3                        | dense_3                          |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "After optimization:\n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                           | Layer                            | Outputs                         \n",
      "———————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                 | input_6                          | conv1d_4                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "input_6                          | conv1d_4                         | max_pooling1d_2                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_4                         | max_pooling1d_2                  | conv1d_5                        \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_2                  | conv1d_5                         | max_pooling1d_3                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "conv1d_5                         | max_pooling1d_3                  | flatten_3                       \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_3                  | flatten_3                        | dense_3                         \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "flatten_3                        | dense_3                          |                                 \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = kerascnn2c.Converter(output_path=Path('gsc_output_fixed'),\n",
    "                           fixed_point=FIXED_POINT, # Number of bits for the fractional part, Q7.9 format\n",
    "                           number_type='int16_t', # Data type for weights/activations (16 bits quantization)\n",
    "                           long_number_type='int32_t', # Data type for intermediate results\n",
    "                           number_min=-(2**15), # Minimum value for 16-bit signed integers\n",
    "                           number_max=(2**15)-1 # Maximum value for 16-bit signed integers\n",
    "                          ).convert_model(copy.deepcopy(model))\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clang: \u001b[0;1;35mwarning: \u001b[0mtreating 'c' input as 'c++' when in C++ mode, this behavior is deprecated [-Wdeprecated]\u001b[0m\n",
      "clang: \u001b[0;1;31merror: \u001b[0mno such file or directory: 'main.cpp'\u001b[0m\n",
      "zsh:1: no such file or directory: ./gsc_fixed\n"
     ]
    }
   ],
   "source": [
    "!g++ -Wall -Wextra -pedantic -Ofast -o gsc_fixed -Igsc_output_fixed/ gsc_output_fixed/model.c main.cpp \n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
